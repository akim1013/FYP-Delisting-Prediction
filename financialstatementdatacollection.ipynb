{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "국내 주식 데이터 수집\n",
    "이번 장에서는 극내 주식 데이터 중 주식티커와 섹터별 구성종목 및 퀀트 투자를 위한 핵심 데이터인 수정주가, 재무제표, 가치지표를 크롤링하는 방법을 알아보겠다.\n",
    "\n",
    "최근 영업일 기준 데이터 받기\n",
    "POST 방식으로 금융 데이터를 제공하는 일부 사이트에서는 쿼리 항목에 특정 날짜를 입력하면(예:20221230) 해당일의 데이터를 다운로드 할 수 있으며, 최근 영업일 날짜를 입력하면 가장 최근의 데이터를 받을 수 있다. 따라서 최근 영업일에 해당하는 항목을 매번 수기로 입력하기 보다는 자동으로 반영되게 할 필요가 있다.\n",
    "\n",
    "네이버 금융의 [국내증시 → 증시자금동향]에는 이전 2영업일에 해당하는 날짜가 있으며, 자동으로 날짜가 업데이트된다. 따라서 해당 부분을 크롤링 한후 날짜에 해당하는 쿼리 항목에 사용하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4)\n",
      "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.12.3 soupsieve-2.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests)\n",
      "  Downloading charset_normalizer-3.4.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Downloading certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Downloading charset_normalizer-3.4.0-cp39-cp39-macosx_11_0_arm64.whl (120 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Installing collected packages: urllib3, idna, charset-normalizer, certifi, requests\n",
      "Successfully installed certifi-2024.8.30 charset-normalizer-3.4.0 idna-3.10 requests-2.32.3 urllib3-2.2.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp39-cp39-macosx_11_0_arm64.whl.metadata (89 kB)\n",
      "Collecting numpy>=1.22.4 (from pandas)\n",
      "  Downloading numpy-2.0.2-cp39-cp39-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/songchaehyun/miniforge3/envs/myenv/lib/python3.9/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/songchaehyun/miniforge3/envs/myenv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.3-cp39-cp39-macosx_11_0_arm64.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mMB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.0.2-cp39-cp39-macosx_14_0_arm64.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-2.0.2 pandas-2.2.3 pytz-2024.2 tzdata-2024.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://finance.naver.com/sise/sise_deposit.nhn\n",
    "\n",
    "개발자도구 화면을 이용해 해당 데이터가 있는 부분을 확인해보면 [클래스가 subtop_sise_graph2인 div 태그 → 클래스가 subtop_chart_note인 ul 태그 → li 태그 → 클래스가 tah인 span 태그]에 위치해 있다는 걸 알 수 있다. 이를 이용해 해당 데이터를 크롤링한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |  2024.10.11\n"
     ]
    }
   ],
   "source": [
    "import requests as rq\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://finance.naver.com/sise/sise_deposit.nhn'\n",
    "data = rq.get(url)\n",
    "data_html = BeautifulSoup(data.content, 'html.parser')\n",
    "parse_day = data_html.select_one(\n",
    "    'div.subtop_sise_graph2 > ul.subtop_chart_note > li > span.tah').text\n",
    "\n",
    "print(parse_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "페이지 주소를 입력한다.\n",
    "get() 함수를 통해 해당 페이지 내용을 받아온다.\n",
    "BeautifulSoup() 함수를 이용해 해당 페이지의 HTML 내용을 BeautifulSoup 객체로 만든다.\n",
    "select_one() 메서드를 통해 해당 태그의 데이터를 추출하며, text 메서드를 이용해 텍스트 데이터만을 추출한다.\n",
    "위 과정을 통해 | yyyy.mm.dd 형식의 데이터가 선택된다. 이 중 숫자 부분만을 뽑아 yyyymmdd 형태로 만들어주도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20241011\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "biz_day = re.findall('[0-9]+', parse_day)\n",
    "biz_day = ''.join(biz_day)\n",
    "\n",
    "print(biz_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. findall() 메서드 내에 정규 표현식을 이용해 숫자에 해당하는 부분만을 추출한다. '[0-9]+' 는 모든 숫자를 의미하는 표현식이다.\n",
    "2. join() 함수를 통해 숫자를 합쳐준다.\n",
    "이를 통해 우리가 원하는 yyyymmdd 형태의 날짜가 만들어졌다. 해당 데이터를 최근 영업일이 필요한 곳에 사용하면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한국거래소의 업종분류 현황 및 개별지표 크롤링\n",
    "주식 관련 데이터를 구하기 위해 가장 먼저 해야하는 일은 어떠한 종목들이 상장되어 있는가에 대한 정보를 구하는 것이다. 한국거래소에서 제공하는 업종분류 현황과 개별종목 지표 데이터를 이용하면 매우 간단하게 해당 정보를 수집할 수 있다.\n",
    "\n",
    "KRX 정보데이터시스템 http://data.krx.co.kr/ 에서 [기본통계 → 주식 → 세부안내] 부분\n",
    "[12025] 업종분류 현황: http://data.krx.co.kr/contents/MDC/MDI/mdiLoader/index.cmd?menuId=MDC0201020506\n",
    "[12021] 개별종목: http://data.krx.co.kr/contents/MDC/MDI/mdiLoader/index.cmd?menuId=MDC0201020502\n",
    "해당 데이터들을 크롤링이 아닌 [Excel] 버튼을 클릭해 엑셀 파일로 받을 수도 있다. 그러나 매번 엑셀 파일을 다운로드하고 이를 불러오는 작업은 상당히 비효율적이며, 크롤링을 이용한다면 해당 데이터를 파이썬에서 바로 불러올 수 있다.\n",
    "\n",
    "업종분류 현황 크롤링\n",
    "먼저 업종분류 현황에 해당하는 페이지에 접속하여 F12를 눌러 개발자도구 화면을 열고 [다운로드] 버튼을 클릭한 후 [CSV]를 누른다. 개발자도구 화면의 [Network] 탭에는 {numref}krx_1와 같이 generate.cmd와 download.cmd 두 가지 항목이 생긴다.\n",
    "\n",
    "거래소에서 엑셀 혹은 CSV 데이터를 받는 과정은 다음과 같다.\n",
    "\n",
    "http://data.krx.co.kr/comm/fileDn/download_excel/download.cmd 에 원하는 항목을 쿼리로 발송하면 해당 쿼리에 해당하는 OTP(generate.cmd)를 받는다.\n",
    "부여받은 OTP를 http://data.krx.co.kr/ 에 제출하면 이에 해당하는 데이터(download.cmd)를 다운로드한다.\n",
    "먼저 1번 단계를 살펴보자. [Headers] 탭의 'General' 항목 중 'Request URL' 부분이 원하는 항목을 제출할 주소다. [Payload] 탭의 Form Data에는 우리가 원하는 항목들이 적혀 있다. 이를 통해 POST 방식으로 데이터를 요청하면 OTP를 받음을 알 수 있다.\n",
    "\n",
    "OTP 생성 부분\n",
    "다음으로 2번 단계를 살펴보자. 'General' 항목의 'Request URL'은 OTP를 제출할 주소다. 'Form Data'의 OTP는 1번 단계를 통해 부여받은 OTP에 해당한다. 이 역시 POST 방식으로 데이터를 요청하며 이를 통해 CSV 파일을 받아온다.\n",
    "\n",
    "위 과정 중 OTP를 받아오는 과정을 코드로 나타내면 다음과 같다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "\n",
      "\t\n",
      "\t\n",
      "\t\t<html>\n",
      "<head>\n",
      "  <title>Error - KRX | Market Data System</title>\n",
      "  <meta charset=\"utf-8\">\n",
      "  <meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\n",
      "  <meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge\">\n",
      "  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1, shrink-to-fit=no\">\n",
      "  <meta name=\"author\" content=\"?????\" />\n",
      "  <meta name=\"description\" content=\"??·????? ????(Marketdata), ?????, ??????(SMILE) ? ?????? ?????? ???? ?? ???\" />\n",
      "  <meta name=\"keywords\" content=\"???????? ?????? ????? ?? KRX?? ??????? ???? ?? ???????? KRX ???????? ??? ?????? ???????? ?????????? ?????\" />\n",
      "  <meta property=\"og:type\" content=\"website\" />\n",
      "  <meta property=\"og:title\" content=\"KRX Market Data System\" />\n",
      "  <meta property=\"og:description\" content=\"??·????? ????(Marketdata), ?????, ??????(SMILE) ? ?????? ?????? ???? ?? ???\" />\n",
      "  <meta name=\"naver-site-verification\" content=\"222ad2f14a7a611c5494c898d311a8d7b61ba13e\"/>\n",
      "  <meta name=\"robots\" content=\"index,follow\" >\n",
      "  <style type=\"text/css\">\n",
      "    .error {position:relative; width:100%; height:100%; background:#f6f7fc; font-family:'Open Sans', sans-serif;}\n",
      "    .error .content {position:absolute; left:50%; top:50%; width:724px; height:224px; padding-left:206px; padding-top:50px; margin:-150px 0 0 -362px; line-height:1.6; font-size:13px; color:#666666; background:url('/comm/error/img/bg_error.png') no-repeat left 0;}\n",
      "    .error .content:after {content:'Market Data System'; display:block; position:absolute; bottom:80px; left:333px; font-weight:600; letter-spacing:-1px;}\n",
      "    .error .content p span {display:block; line-height:1; margin-bottom:13px; font-size:20px; font-weight:600; color:#00b4d5;}\n",
      "    .error .btnWrap {position:absolute; left:0; top:50%; width:100%; margin:90px 0 20px 0; text-align:center;}\n",
      "    .error .btnWrap a {display:inline-block; background:#7070e7; color:#eeeeee; padding:10px 30px 10px 30px; border-radius:8px; font-size:15px; font-weight:600; text-decoration:none;}\n",
      "  </style>\n",
      "</head>\n",
      "<body class=\"error\">\n",
      "<div class=\"content\">\n",
      "  <p>\n",
      "    <span>Service unavailable</span>\n",
      "    The service is not smooth due to temporary access instability.<br>\n",
      "    If you have any questions about this, please contact system manager.\n",
      "  </p>\n",
      "</div>\n",
      "<div class=\"btnWrap\"><a href=\"http://data.krx.co.kr/contents/MDC/MAIN/main/index.cmd\">MAIN</a></div>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "\t\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests as rq\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "\n",
    "gen_otp_url = 'http://data.krx.co.kr/comm/fileDn/GenerateOTP/generate.cmd'\n",
    "gen_otp_stk = {\n",
    "    'mktId': 'STK',\n",
    "    'trdDd': biz_day,\n",
    "    'money': '1',\n",
    "    'csvxls_isNo': 'false',\n",
    "    'name': 'fileDown',\n",
    "    'url': 'dbms/MDC/STAT/standard/MDCSTAT03901'\n",
    "}\n",
    "headers = {'Referer': 'http://data.krx.co.kr/contents/MDC/MDI/mdiLoader'}\n",
    "otp_stk = rq.post(gen_otp_url, gen_otp_stk, headers=headers).text\n",
    "\n",
    "print(otp_stk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gen_otp_url 에 원하는 항목을 제출할 URL을 입력한다.\n",
    "개발자도구 화면에 있는 쿼리 내용들을 딕셔너리 형태로 입력한다. 이 중 mktId의 'STK'는 코스피에 해당하며, 코스닥 데이터를 받고자 할 경우 'KSQ'를 입력하면 된다.\n",
    "영업일을 뜻하는 trdDd에는 위에서 구한 최근 영업일 데이터를 입력한다.\n",
    "헤더 부분에 리퍼러(Referer)를 추가한다. 리퍼러란 링크를 통해서 각각의 웹사이트로 방문할 때 남는 흔적이다. 거래소 데이터를 다운로드하는 과정을 살펴보면 첫 번째 URL에서 OTP를 부여받고, 이를 다시 두번째 URL에 제출했다. 그런데 이러한 과정의 흔적이 없이 OTP를 바로 두번째 URL에 제출하면 서버는 이를 로봇으로 인식해 데이터를 주지 않는다. 따라서 헤더 부분에 우리가 거쳐온 과정을 흔적으로 남겨야 데이터를 받을 수 있다. 이러한 리퍼러 주소는 개발자도구 화면에서도 확인할 수 있다({numref}referer).\n",
    "post() 함수를 통해 해당 URL에 쿼리를 전송하면 이에 해당하는 데이터를 받으며, 이 중 텍스트에 해당하는 내용만 불러온다.\n",
    "\n",
    "위의 과정을 거쳐 생성된 OTP를 제출하면, 우리가 원하는 데이터를 다운로드할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;HTML&gt;&lt;HEAD&gt;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;TITLE&gt;Access Denied&lt;/TITLE&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;/HEAD&gt;&lt;BODY&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;H1&gt;Access Denied&lt;/H1&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You don't have permission to access \"http&amp;#58;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reference&amp;#32;&amp;#35;18&amp;#46;3e0ed317&amp;#46;1728991...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;P&gt;https&amp;#58;&amp;#47;&amp;#47;errors&amp;#46;edgesuite&amp;#4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;/BODY&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;/HTML&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        <HTML><HEAD>\n",
       "0                       <TITLE>Access Denied</TITLE>\n",
       "1                                      </HEAD><BODY>\n",
       "2                             <H1>Access Denied</H1>\n",
       "3  You don't have permission to access \"http&#58;...\n",
       "4  Reference&#32;&#35;18&#46;3e0ed317&#46;1728991...\n",
       "5  <P>https&#58;&#47;&#47;errors&#46;edgesuite&#4...\n",
       "6                                            </BODY>\n",
       "7                                            </HTML>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "down_url = 'http://data.krx.co.kr/comm/fileDn/download_csv/download.cmd'\n",
    "down_sector_stk = rq.post(down_url, {'code': otp_stk}, headers=headers)\n",
    "sector_stk = pd.read_csv(BytesIO(down_sector_stk.content), encoding='EUC-KR')\n",
    "\n",
    "sector_stk"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
